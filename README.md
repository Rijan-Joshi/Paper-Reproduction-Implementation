# ğŸ§  From-Scratch: Deep Learning Paper Implementations

![Python](https://img.shields.io/badge/Python-3.8%2B-blue)
![Status](https://img.shields.io/badge/Status-Active-success)
![Schedule](https://img.shields.io/badge/New%20Implementation-Every%20Friday-blueviolet)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)

> *"What I cannot create, I do not understand."* â€” Richard Feynman
><!-- <img width="687" height="440" alt="image" src="https://github.com/user-attachments/assets/694f01ff-a0c8-47af-ab14-a73501c150d0" /> -->


## ğŸ“– About This Repository
This repository documents my journey of **implementing, replicating, and experimenting** with seminal Deep Learning papers and architectures from scratch.

**The Goal:** To demystify the "black box" of neural networks.
## ğŸ“œ The Rule
_No pre-built model imports (e.g., torchvision.models). Every layer, training loop, and architecture is built from the ground up to understand the internal mechanics. Implementations will use either:

NumPy: For true, low-level mathematical implementation of all operations (convolution, backprop, optimizers).

PyTorch Tensors: For high-level implementations leveraging CUDA and automatic differentiation where desired._

## ğŸ—“ï¸ The Schedule
I commit to adding a new implementation **every Friday**.

---

## ğŸš€ Progress & Benchmarks

| SN | Paper / Architecture | Domain | Key Concepts | Result | Status | Code |
|:--:|:---|:---|:---|:---|:--:|:--:|
| **01** | **[LeNet-5 (LeCun et al., 1998)](http://yann.lecun.com/exdb/publis/pdf/lecun-01a.pdf)** | CV | CNN, Tanh, AvgPool | 98.4% Acc | âœ… | [ğŸ“‚ View](/01_lenet5_1998) |
| **02** | *Next Paper...* | â€” | â€” | â€” | ğŸš§ | â€” |
| **03** | â€” | â€” | â€” | â€” | â³ | â€” |
| **04** | â€” | â€” | â€” | â€” | â³ | â€” |
| **05** | â€” | â€” | â€” | â€” | â³ | â€” |
| **06** | â€” | â€” | â€” | â€” | â³ | â€” |
| **07** | â€” | â€” | â€” | â€” | â³ | â€” |
| **08** | â€” | â€” | â€” | â€” | â³ | â€” |
| **09** | â€” | â€” | â€” | â€” | â³ | â€” |
| **10** | â€” | â€” | â€” | â€” | â³ | â€” |
| **11** | â€” | â€” | â€” | â€” | â³ | â€” |
| **12** | â€” | â€” | â€” | â€” | â³ | â€” |

---

## ğŸ“‚ Repository Structure

Each paper is contained in its own folder to keep the environment self-contained.

```text
â”œâ”€â”€ 01_lenet5_1998/
â”‚   â”œâ”€â”€ model.py         # The model architecture (from scratch)
â”‚   â”œâ”€â”€ train.py         # Training loop
â”‚   â”œâ”€â”€ utils.py         # Data loading and helper functions
â”‚   â”œâ”€â”€ notebooks/       # EDA and Visualization experiments
â”‚   â””â”€â”€ README.md        # Specific results/notes for this paper
â”œâ”€â”€ 02_next_paper/
â”œâ”€â”€ common/              # Shared utilities (logging, metrics)
â””â”€â”€ README.md

```
## ğŸ› ï¸ Getting Started

Follow these steps to set up the project locally.

### 1. Clone the repository

```bash
git clone [https://github.com/your-username/your-repo-name.git](https://github.com/your-username/your-repo-name.git)
cd your-repo-name

```
## 2. Run a specific implementation
Navigate to the specific folder to run
```bash
cd 01_lenet5_1998
python train.py
